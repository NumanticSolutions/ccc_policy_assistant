{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T00:13:03.889470Z",
     "start_time": "2024-12-03T00:13:03.886710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the Pyppeteer Puppeteer wrapper\n",
    "\n",
    "\n",
    "# References\n",
    "# - https://scrapeops.io/python-web-scraping-playbook/python-pyppeteer/\n",
    "# - Note Chromium installed at /Users/stephengodfrey/Library/Application Support/pyppeteer/local-chromium/1181205\n",
    "# - https://medium.com/@alexandrdzhumurat/leveraging-chatgpt-for-html-parsing-a-game-changer-rendering-regular-expressions-obsolete-5d8779d761ba\n"
   ],
   "id": "1678e959386006a6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:04:58.431498Z",
     "start_time": "2024-12-03T02:04:58.186694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "import sys, os\n",
    "\n",
    "\n",
    "from pyppeteer import launch\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pydantic import BaseModel\n",
    "import openai\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../../utils/\")\n",
    "# os.listdir(\"../../utils/\")\n",
    "import authentication as au\n",
    "\n",
    "\n"
   ],
   "id": "a25681c13cb427c5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get page content",
   "id": "ac39fd385601f8a5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T02:05:01.964406Z",
     "start_time": "2024-12-03T02:05:00.052361Z"
    }
   },
   "source": [
    "\n",
    "# Get a screenshot of page\n",
    "# async def main():\n",
    "#     browser = await launch()\n",
    "#     page = await browser.newPage()\n",
    "#     await page.goto('https://quotes.toscrape.com/')\n",
    "#     await page.screenshot({'path': 'screenshot.png'})\n",
    "#     await browser.close()\n",
    "\n",
    "# Get the html content and view with beautiful soup\n",
    "async def main():\n",
    "    browser = await launch()\n",
    "    page = await browser.newPage()\n",
    "    await page.goto('https://www.cccco.edu/')\n",
    "\n",
    "    ## Get HTML\n",
    "    html = await page.content()\n",
    "    await browser.close()\n",
    "    return html\n",
    "\n",
    "html_response = await main()\n",
    "\n",
    "## Load HTML Response Into BeautifulSoup\n",
    "soup = BeautifulSoup(html_response, \"html.parser\")\n",
    "\n",
    "## Get the HTML code in a string\n",
    "html_code_string = str(soup)\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:05:01.968694Z",
     "start_time": "2024-12-03T02:05:01.967016Z"
    }
   },
   "cell_type": "code",
   "source": "# dir(soup)",
   "id": "e837f065728d8333",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:15:21.350579Z",
     "start_time": "2024-12-03T02:15:21.339011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "soup\n",
    "\n",
    "# Return all links in a tags with href values\n",
    "page_urls = []\n",
    "for a in soup.find_all('a', href=True):\n",
    "    # print(\"Found the URL:\", a['href'])\n",
    "    # page_urls.append((a.contents, a['href']))\n",
    "    page_urls.append(a['href'])\n",
    "\n",
    "print(\"The full length of this page's HTML content is {} characters long\".format(len(str(soup))))\n",
    "print()\n",
    "print(\"There are {} <a tags with href values on this page\".format(len(page_urls)))\n",
    "print(\"There contain {} unique URLs\".format(len(set(page_urls))))\n",
    "\n",
    "atagloc = html_code_string.find(\"<a\")\n",
    "print(\"here's an example of an <a tag\")\n",
    "print(html_code_string[atagloc:atagloc+100])\n",
    "print()\n",
    "\n",
    "page_texts = []\n",
    "for p in soup.find_all('p'):\n",
    "    page_texts.append(p.text)\n",
    "\n",
    "print(\"There are {} <p /p> tags on this page\".format(len(page_texts)))\n",
    "print(\"here's an example of an <p tag\")\n",
    "ptagloc = html_code_string.find(\"<p\")\n",
    "\n",
    "print(html_code_string[ptagloc:ptagloc+100])\n",
    "\n"
   ],
   "id": "fecafc0c7162d2bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full length of this page's HTML content is 38734 characters long\n",
      "\n",
      "There are 94 <a tags with href values on this page\n",
      "There contain 44 unique URLs\n",
      "here's an example of an <a tag\n",
      "<a href=\"#page-banner\">Skip to Main Content</a></div>\n",
      "<nav aria-label=\"Utility Links\" class=\"utility\n",
      "\n",
      "There are 19 <p /p> tags on this page\n",
      "here's an example of an <p tag\n",
      "<p>Learn about career paths and career education opportunities designed to get you into good-paying \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Use chatGPT to convert the HTML string to structured data",
   "id": "db787097a57c7f96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:05:33.213986Z",
     "start_time": "2024-12-03T02:05:23.115308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set API Key\n",
    "au_config = au.ApiAuthentication()\n",
    "os.environ[\"OPENAI_API_KEY\"] = au_config.apis_configs[\"OPENAI_KEY\"]\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "class HTMLExtraction(BaseModel):\n",
    "    title: str\n",
    "    urls: list[str]\n",
    "    texts: list[str]\n",
    "\n",
    "system_prompt = (\"You are an expert at converting HTML code to structured data. \"\n",
    "                 \"You will be given semi-structured HTML code in the form of a string. \"\n",
    "                 \"You should extract structured data from it \"\n",
    "                 \"and return the requested information. \"\n",
    "                 \"Definitions of expected output: \"\n",
    "                 \"urls can be found in the href field inside text blocks opened with <a and closed with </a>\"\n",
    "                 \"texts can be found in inside text blocks opened with <p and closed with </p>\")\n",
    "\n",
    "html_code_string = str(soup)\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": html_code_string}\n",
    "    ],\n",
    "    response_format=HTMLExtraction,\n",
    ")\n",
    "\n",
    "gpt_response = completion.choices[0].message.parsed\n",
    "\n",
    "# get the html extraction model in a dictionary\n",
    "hsd = gpt_response.model_dump()\n"
   ],
   "id": "6e88ce033a263c3e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:16:42.643908Z",
     "start_time": "2024-12-03T02:16:42.640195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"chatGPT found {} URLs on this page representing {} unique URLs\".format(len(hsd['urls']),\n",
    "                                                                              len(set(hsd['urls']))))\n",
    "\n",
    "# Compare techniques for extracting URLs\n",
    "urls_in_ai_not_bs = [u for u in hsd['urls'] if u not in page_urls]\n",
    "urls_in_bs_not_in_ai  = [u for u in page_urls if u not in hsd['urls']]\n",
    "print(\"These URLs were found using BeautifulSoup but not chatGPT\")\n",
    "print(urls_in_ai_not_bs)\n",
    "print(\"These URLs were found by chatGPT but not BeautifulSoup\")\n",
    "print(urls_in_bs_not_in_ai)\n"
   ],
   "id": "827b989cd399b733",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatGPT found 51 URLs on this page representing 42 unique URLs\n",
      "These URLs were found using BeautifulSoup but not chatGPT\n",
      "[]\n",
      "These URLs were found by chatGPT but not BeautifulSoup\n",
      "['#page-banner', 'Search-Results#site-search-bar']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:17:07.499358Z",
     "start_time": "2024-12-03T02:17:07.496253Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"chatGPT found {} texts on this page\".format(len(hsd['texts'])))",
   "id": "70eb32fc3fb36c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatGPT found 7 texts on this page\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee7aba724a00989a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
